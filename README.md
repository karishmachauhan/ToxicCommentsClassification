# Toxic Comments Classification

### Background
Today social media platforms are very prevalent and people spend most of their time on these platforms. Sometimes, people are directly or indirectly attacked on comments section of these websites which directly affect mental health of people. Hence, it is very crucial to identify such toxic comments and remove them as required.

### Goal
While identifying toxic comments from social media Machine Learning Models are bound to have a bias in the model for certain sensitive categories. For example if some abusive comments use word 'gay' a lot then it will classify even non-toxic comments as toxic which contains this word. Our goal is to minimize this unintended bias in the model while classifying the comments from Data Source:Online Hate Index Research Project at D-Lab, University of California, Berkeley.

### Notebook of detailed code
<a href='https://github.com/karishmachauhan/ToxicCommentsClassification/blob/main/LSTMandGRU.ipynb'>Toxic Comments Classifier</a>

### Outcome
We were able to minimize the unintended bias from the comments for certain sensitive groups. Please refer following diagram for accuracy metric across different subgroups.


